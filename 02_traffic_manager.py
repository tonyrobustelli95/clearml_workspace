# the following script concatenates all csv files generated by script 01_traffic_concatenator.py 
# performs data standardization/normalization of the whole dataframe

import pandas as pd
import os
import numpy as np

def minmax_dataframe(df):

    numeric_cols = df.select_dtypes(include=[float, int]).columns.tolist()

    original_column_names = df[numeric_cols].columns.tolist()

    for col in numeric_cols:
        df[col] = (df[col] - df[col].min()) / (df[col].max() - df[col].min())

    df[numeric_cols].columns = original_column_names


if __name__ == '__main__':

    dfList = []
    catInfo = dict()

    # loads of each .csv files as dataframe
    catList = sorted(os.listdir('./dataset/processed/'))

    for cat in catList:

        df = pd.read_csv('./dataset/processed/' + cat)
        
        if df.__len__() > 0: 
            
            dfList.append(df)
            catInfo[cat] = df.__len__()

    # dataframe concatenation
    df = pd.concat(dfList)

    # dataframe normalization/standardization
    minmax_dataframe(df)

    indexList = []

    for cat in catList: 
        
        if indexList.__len__() == 0: indexList.append(catInfo[cat])
        else: indexList.append(indexList[indexList.__len__() - 1] + catInfo[cat])
    
    indexList.pop()

    # split the scaled dataframe into corresponding traffic dataframes
    dfNumpy = df.to_numpy()
    dfNumpy = np.split(dfNumpy,indexList)

    for i in range(catList.__len__()):
    
        dfApp = pd.DataFrame(dfNumpy[i],columns=df.columns)
        dfApp.to_csv('./dataset/scaled/' + catList[i],index=False)
